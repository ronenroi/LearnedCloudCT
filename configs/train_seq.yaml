hydra:
  run:
    dir: ../outputs/${now:%Y-%m-%d}_BOMEX_Res50_FPN_512channels_Sampl_3_9_10cams_CE_LR3e-06_SEQ_resume_training_seq/${now:%H-%M-%S}
#    dir: ../outputs/${now:%Y-%m-%d}_tmp/${now:%H-%M-%S}
seed: 0
debug: False
resume: True
stats_print_interval: 25
validation_iter_interval: 2500
checkpoint_iteration_interval: 5000
checkpoint_resume_path: '/wdata/roironen/Deploy/ProbCT/outputs/2023-03-05_BOMEX_Res50_FPN_512channels_Sampl_3_9_10cams_CE_LR5.0e-05_FixCT_wd1.0e-05_n_sampling_nets10_Gcam_64_Gdomain_64_SEQ/17-41-58/checkpoints/cp_340000.pth'
gpu: 0
data:
  dataset_name: 'BOMEX_10cameras_20m'
  n_training: -1
  n_val: 20
  n_cam: 10
  rand_cam: False
  mean: 0.017
  std: 0.0072
augmentation:
  noise: 'gaussian'
  std: 0.05
optimizer:
  max_epochs: 100000
  lr: 3.0e-06 #5.0e-05
  wd: 1.0e-05
  batch_size: 1
  iter_steps: [1000000000]
  lr_scheduler_gamma: 0.1
  loss: 'CE' #'L2_relative_error' # 'CE'
  ce_weight_zero: True
cross_entropy:
  min: 0
  max: 300
  bins: 301
ct_net:
  n_hidden_neurons_xyz: 64
  n_hidden_neurons_dir: 64
  n_layers_xyz: 4
  n_layers_dir: 4
  append_xyz: [2]
  append_dir: [2]
  n_query: 40
  val_n_query: 20
  stop_encoder_grad: False
  mask_type: 'space_carving'  #'space_carving' 'gt_mask' None
  val_mask_type: 'space_carving' #'space_carving'  #'space_carving' 'gt_mask' None
  query_point_method: 'toa_random' #'topk' gt_sc_random
  query_point_val_method: 'toa_all'
  use_neighbours: False # penalize model also for voxel neighbours

backbone:
  name: 'resnet50_fpn' #'resnet34' fasterrcnn_resnet50_fpn
  pretrained: False
  num_layers: 4
  index_interp: 'bilinear'
  index_padding: 'zeros' #'zeros', 'border', or 'reflection'
  upsample_interp: 'bilinear'
  feature_scale: 1.0
  use_first_pool: 'batch'
  sampling_support: 3
  sampling_output_size: 9
  out_channels: 512
  n_sampling_nets: 10
  feature_flatten: False
  modify_first_layer: True

decoder:
  name: 'CE' #'CE' #FixCTv4_CE
  type: 'transformer' #mlp transformer
  masked: False
  num_masked: 20
  average_cams: False
  feature_flatten: True

transformer:
  hidden_dim: 256
  dropout: 0.1
  nheads: 4
  dim_feedforward: 1024
  num_encoder_layers: 6
  num_decoder_layers: 6
  normalize_before: True
  training_seq_iter: 0
